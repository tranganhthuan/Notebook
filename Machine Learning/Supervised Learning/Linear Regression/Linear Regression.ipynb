{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Mathematics:\n",
    "### Linear Regression: \n",
    "$$ y \\approx  f(\\mathbf{x}) = \\hat{y} $$\n",
    "$$ \\text{where: } f(\\mathbf{x}) =w_1 x_1 + w_2 x_2 + w_3 x_3 + w_0$$\n",
    "$$ \\Rightarrow y \\approx \\mathbf{\\bar{x}}\\mathbf{w} = \\hat{y} ~~~(1)$$\n",
    "Note:\n",
    "\n",
    "- $\\mathbf{\\bar{x}} = [1, x_1, x_2, x_3]$ (row vector)\n",
    "- $\\mathbf{w} = [w_0, w_1, w_2, w_3]^T$ (column vector)\n",
    "\n",
    "###  Loss function:\n",
    "$$ \\frac{1}{2}e^2 = \\frac{1}{2}(y - \\hat{y})^2 = \\frac{1}{2}(y - \\mathbf{\\bar{x}}\\mathbf{w})^2 $$\n",
    "Note:\n",
    "- $\\frac{1}{2}$ is used to facilitates the caculation process (when calculate the derivative $\\frac{1}{2}$ will be eliminated).\n",
    "- We use $e^2$ instead of $|e|$ because it has derivative at any point, while the derivative of $|e|$ is not identified at 0.\n",
    "\n",
    "### Cost function:\n",
    "$$\\mathcal{L}(\\mathbf{w}) = \\frac{1}{2}\\sum_{i=1}^N (y_i - \\mathbf{\\bar{x}}_i\\mathbf{w})^2$$\n",
    "$$= \\frac{1}{2}\\|\\mathbf{y} - \\mathbf{\\bar{X}}\\mathbf{w} \\|_2^2$$\n",
    "Note:\n",
    "- $\\| \\mathbf{z} \\|_2^2$ is the sum of the square of all point in $\\mathbf{z}$\n",
    "\n",
    "### Derivative:\n",
    "To choose theta which can minimize the cost function, we need to calculate the derivative first.\n",
    "$$\\frac{\\partial{\\mathcal{L}(\\mathbf{w})}}{\\partial{\\mathbf{w}}} = \\frac{1}{2}(\\|\\mathbf{y} - \\mathbf{\\bar{X}}\\mathbf{w} \\|_2^2)'$$\n",
    "$$= -\\frac{1}{2}(\\|\\mathbf{\\bar{X}}\\mathbf{w} - \\mathbf{y} \\|_2^2)'$$\n",
    "$$= -\\frac{1}{2}2\\mathbf{\\bar{X}}^T(\\mathbf{\\bar{X}}\\mathbf{w} - \\mathbf{y})$$\n",
    "$$= \\mathbf{\\bar{X}}^T(\\mathbf{y} - \\mathbf{\\bar{X}}\\mathbf{w})$$\n",
    "Note:\n",
    "- $(\\|\\mathbf{A}\\mathbf{x} - \\mathbf{b} \\|_2^2)' = 2\\mathbf{A}^T(\\mathbf{A}\\mathbf{x} - \\mathbf{b})$\n",
    "\n",
    "### Theta:\n",
    "After finding the derivative, we assign the derivative equal to 0.\n",
    "$$\\mathbf{\\bar{X}}^T(\\mathbf{y} - \\mathbf{\\bar{X}}\\mathbf{w})=0$$\n",
    "$$\\mathbf{\\bar{X}}^T\\mathbf{\\bar{X}}\\mathbf{w} = \\mathbf{\\bar{X}}^T\\mathbf{y}$$\n",
    "$$\\mathbf{w}= (\\mathbf{\\bar{X}}^T\\mathbf{\\bar{X}})^{\\dagger} \\mathbf{\\bar{X}}^T\\mathbf{y} ~~~(2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Code:\n",
    "- Step 1: Use the formular $(2)$ to calculate $\\mathbf{w}$.\n",
    "- Step 2: Use the formular $(1)$ to calculate $\\hat{y}$ based on $\\mathbf{X}$ and $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate theta\n",
    "def calculate_theta(X_train, y_train):\n",
    "    X_bar = np.c_[np.ones(X_train.shape), X_train]\n",
    "    theta = np.dot(np.linalg.pinv(np.dot(X_bar.T, X_bar)), np.dot(X_bar.T, y_train))\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the new values\n",
    "def predict(X_test, theta):\n",
    "    X_bar = np.c_[np.ones(X_test.shape), X_test]\n",
    "    y_pre = np.dot(X_bar, theta)\n",
    "    return y_pre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the height based on weight.\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th style=\"text-align: center\">Height (cm)</th>\n",
    "      <th style=\"text-align: center\">Weight (kg)</th>\n",
    "      <th style=\"text-align: center\">Height (cm)</th>\n",
    "      <th style=\"text-align: center\">Weight (kg)</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td style=\"text-align: center\">147</td>\n",
    "      <td style=\"text-align: center\">49</td>\n",
    "      <td style=\"text-align: center\">168</td>\n",
    "      <td style=\"text-align: center\">60</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"text-align: center\">150</td>\n",
    "      <td style=\"text-align: center\">50</td>\n",
    "      <td style=\"text-align: center\">170</td>\n",
    "      <td style=\"text-align: center\">72</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"text-align: center\">153</td>\n",
    "      <td style=\"text-align: center\">51</td>\n",
    "      <td style=\"text-align: center\">173</td>\n",
    "      <td style=\"text-align: center\">63</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"text-align: center\">155</td>\n",
    "      <td style=\"text-align: center\">52</td>\n",
    "      <td style=\"text-align: center\">175</td>\n",
    "      <td style=\"text-align: center\">64</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"text-align: center\">158</td>\n",
    "      <td style=\"text-align: center\">54</td>\n",
    "      <td style=\"text-align: center\">178</td>\n",
    "      <td style=\"text-align: center\">66</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"text-align: center\">160</td>\n",
    "      <td style=\"text-align: center\">56</td>\n",
    "      <td style=\"text-align: center\">180</td>\n",
    "      <td style=\"text-align: center\">67</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"text-align: center\">163</td>\n",
    "      <td style=\"text-align: center\">58</td>\n",
    "      <td style=\"text-align: center\">183</td>\n",
    "      <td style=\"text-align: center\">68</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td style=\"text-align: center\">165</td>\n",
    "      <td style=\"text-align: center\">59</td>\n",
    "      <td style=\"text-align: center\">&nbsp;</td>\n",
    "      <td style=\"text-align: center\">&nbsp;</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[52.94135889]\n",
      " [55.7373837 ]]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_train = np.array([147, 150, 153, 158, 163, 165, 168, 170, 173, 175, 178, 180, 183]).reshape(-1,1)\n",
    "y_train = np.array([ 49, 50, 51,  54, 58, 59, 60, 62, 63, 64, 66, 67, 68]).reshape(-1,1)\n",
    "# Calculate theta\n",
    "theta = calculate_theta(X_train, y_train)\n",
    "# Predict\n",
    "X_test = np.array([155, 160]).reshape(-1,1)\n",
    "y_pre = predict(X_test, theta)\n",
    "print (y_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III.Preference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning cơ bản - Bài 3: Linear Regression [https://machinelearningcoban.com/2016/12/28/linearregression/]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
