{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Algorithm\n",
    "### Naive Bayes Classifier\n",
    "$$\\begin{eqnarray}\n",
    "    c & = & \\arg\\max_c p(c | \\mathbf{x}) & (1) \\\\\n",
    "      & = & \\arg\\max_c \\frac{p(\\mathbf{x} | c) p(c)}{p(\\mathbf{x})} ~~~& (2)\\\\\n",
    "      & = & \\arg\\max_c p(\\mathbf{x} | c) p(c) & (3)\\\\\n",
    "\\end{eqnarray}$$\n",
    "Explain:\n",
    "- (1): We choose the class with have highest probability.\n",
    "- (2): Using Bayes' theorem.\n",
    "- (3): Simplify the formular by removing $p(\\mathbf{x})$ because it is not related to $c$\n",
    "\n",
    "### Multinomial Naive Bayes\n",
    "$$\\lambda_{ci} = p(x_i | c) = \\frac{N_{ci}}{N_c}$$\n",
    "Note:\n",
    "- To avoid numerator equal to 0, we use Laplace smoothing.\n",
    "- Laplace smoothing: $\\hat{\\lambda}_{ci} = \\frac{N_{ci} + \\alpha}{N_{c} + d\\alpha}$\n",
    "    - $\\alpha$ is an integer (ussually equal to 1).\n",
    "    - $d$ is the number of unique words. \n",
    "\n",
    "### Bernoulli Naive Bayes\n",
    "$$p(x_i | c) = p(i | c)^{x_i} (1 - p(i | c)) ^{1 - x_i}$$\n",
    "Note:\n",
    "- To avoid numerator equal to 0, we use Laplace smoothing.\n",
    "- Laplace smoothing: $p(i | c) = \\frac{Nc_i + \\alpha}{Nc + 2\\alpha}$\n",
    "    - $\\alpha$ is an integer (ussually equal to 1).\n",
    "    - $Nc_i$ is number of instances in class c contain word i.\n",
    "    - $Nc$ is number of instances in class c."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Code\n",
    "Multinomial Naive Bayes:\n",
    "- Step 1: Calculate the probabilities of each class in y_train $p(c)$.\n",
    "- Step 2: Calculate the probabilities of each element in each class $p(x_i | c)$.\n",
    "- Step 3: Use Naive Bayes formula to predict labels of new dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NaiveBayesClassifier(object):\n",
    "    def __init__(self, method = \"multinomial\"):\n",
    "        self.X_train = np.array([])\n",
    "        self.y_train = np.array([])\n",
    "        self.X_predict = np.array([])\n",
    "        self.y_predict = np.array([])\n",
    "        self.classes = np.array([])\n",
    "        self.count = np.array([])\n",
    "        self.Px = np.array([])\n",
    "        self.Pxc = np.array([])\n",
    "        self.probability = np.array([])\n",
    "        self.method = method \n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = np.copy(X_train)\n",
    "        self.y_train = y_train\n",
    "        self.classes, self.count = np.unique(self.y_train, return_counts=True)\n",
    "    def calculate_Px(self):\n",
    "        self.Px = self.count/self.count.sum(axis=0)\n",
    "    def calculate_Pxc(self):\n",
    "        num_classes = self.classes.shape[0]\n",
    "        d = self.X_train.shape[1]\n",
    "        self.Pxc = np.zeros((num_classes, d))\n",
    "        if self.method == \"multinomial\":\n",
    "            for i in range(num_classes):\n",
    "                table = self.X_train[np.where(self.y_train == self.classes[i])]\n",
    "                total = np.sum(table, axis=0)\n",
    "                self.Pxc[i] = (total+1)/(total.sum()+d)\n",
    "        elif self.method == \"bernoulli\":\n",
    "            self.X_train[self.X_train >= 1] = 1\n",
    "            for i in range(num_classes):\n",
    "                table = self.X_train[np.where(self.y_train == self.classes[i])]\n",
    "                total = np.sum(table, axis=0)\n",
    "                self.Pxc[i] = (total+1)/(table.shape[0]+2)  \n",
    "    def predict(self, X_predict):\n",
    "        self.X_predict = X_predict\n",
    "        self.calculate_Px()\n",
    "        self.calculate_Pxc()\n",
    "        num_classes = self.classes.shape[0]\n",
    "        N = self.X_predict.shape[0]\n",
    "        d = self.X_predict.shape[1]\n",
    "        self.probability = np.zeros((N, num_classes))\n",
    "        if self.method == \"multinomial\":\n",
    "            for i in range(N):\n",
    "                for j in range(num_classes):\n",
    "                    power = np.power(self.Pxc[j],self.X_predict[i])\n",
    "                    self.probability[i][j] = np.prod(power)\n",
    "        elif self.method == \"bernoulli\":\n",
    "            self.X_predict[self.X_predict >= 1] = 1\n",
    "            for i in range(N):\n",
    "                for j in range(num_classes):\n",
    "                    power = self.Pxc[j]*self.X_predict[i]+(1-self.Pxc[j])*(1-self.X_predict[i])\n",
    "                    self.probability[i][j] = np.prod(power)\n",
    "        self.probability = np.multiply(self.probability, self.Px)\n",
    "        self.probability = np.divide(self.probability, self.probability.sum(axis=1).reshape(-1, 1))\n",
    "        self.y_predict = self.classes[np.argmax(self.probability, axis=1)]\n",
    "        return self.y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data\n",
    "d1 = [2, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "d2 = [1, 1, 0, 1, 1, 0, 0, 0, 0]\n",
    "d3 = [0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
    "d4 = [0, 1, 0, 0, 0, 0, 1, 1, 1]\n",
    "\n",
    "train_data = np.array([d1, d2, d3, d4])\n",
    "label = np.array(['B', 'B', 'B', 'N']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayesClassifier(method = \"bernoulli\")\n",
    "model.fit(train_data,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "d5 = np.array([[2, 0, 0, 1, 0, 0, 0, 1, 0]])\n",
    "d6 = np.array([[0, 1, 0, 0, 0, 0, 0, 1, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N'], dtype='<U1')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(d6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16948581, 0.83051419]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.probability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
